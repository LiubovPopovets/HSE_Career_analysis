{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import json\n",
    "\n",
    "def get_date(yyyy, mm, dd):\n",
    "    g = dd+'/'+mm_eng[mm.capitalize()]+'/'+yyyy\n",
    "    d = datetime.datetime.strptime(g, '%d/%b/%Y').date()\n",
    "    return d\n",
    "\n",
    "def main():\n",
    "    mm_eng = {'Янв':'Jan', 'Фев':'Feb', 'Мар':'Mar', 'Апр':'Apr',\n",
    "     'Мая':'May', 'Июн':'Jun', 'Июл':'Jul', 'Авг':'Aug', \n",
    "     'Сен':'Sep', 'Окт':'Oct', 'Ноя':'Nov', 'Дек':'Dec'}\n",
    "\n",
    "    message = ('Внимание, Пользователь! Выполняю запросы на веб-сайт'+\n",
    "               '\\n(анг. \"website\") посредсвом информационно-телекоммуникационной'+\n",
    "               '\\nсети Интернет (анг. \"Internet\"). Сохраняйте сопкойствие'+\n",
    "               '\\nи бодрость духа до появления новых указанй или характерного звука.')\n",
    "\n",
    "    m_r = requests.get('https://career.hse.ru/news/')\n",
    "    soup = BeautifulSoup(m_r.text, 'lxml')\n",
    "    num_of_cycles = int(soup.find_all('a', {'class' : 'pages__page'})[-1].text)\n",
    "    hse_career_posts = []\n",
    "\n",
    "    print(message)\n",
    "\n",
    "    with tqdm_notebook(total=num_of_cycles) as pbar:\n",
    "\n",
    "        for i in range(num_of_cycles):\n",
    "\n",
    "            r = requests.get(f'https://career.hse.ru/news/page{i}.html')\n",
    "            soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "            posts_content = soup.find_all(\"div\", {\"class\": \"post__content\"})\n",
    "            posts_meta = soup.find_all(\"div\", {\"class\": \"post-meta__date\"})\n",
    "\n",
    "            qq = list(zip(posts_content, posts_meta))\n",
    "\n",
    "            for e in qq:\n",
    "\n",
    "                title = e[0].find('a').text\n",
    "                href = e[0].find('a')['href']\n",
    "                text_content = e[0].find('div', {'class' : 'post__text'}).text\n",
    "\n",
    "                dd = e[1].find('div', {'class' : 'post-meta__day'}).text\n",
    "                mm = e[1].find('div', {'class' : 'post-meta__month'}).text\n",
    "                yyyy = e[1].find('div', {'class' : 'post-meta__year'}).text\n",
    "\n",
    "                d = str(get_date(yyyy, mm, dd))\n",
    "\n",
    "                e_dict = {'title':title, 'href':href, \n",
    "                          'text_content':text_content, 'date':d}\n",
    "\n",
    "                hse_career_posts.append(e_dict)\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "    print(\"Now we have got all news-posts\")  \n",
    "\n",
    "    print(message)\n",
    "\n",
    "    with tqdm_notebook(total=len(hse_career_posts)) as pbar:\n",
    "\n",
    "        for e in hse_career_posts:\n",
    "            try:\n",
    "                url = e['href']\n",
    "                if 'http:' in url:\n",
    "                    url = url.replace('http:', 'https:')\n",
    "                if not 'https:' in url:\n",
    "                    url = 'https:'+url\n",
    "                r = requests.get(url).text\n",
    "                e['href_content_html'] = r\n",
    "            except:\n",
    "                e['href_content_html'] = ''\n",
    "                pass\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "    print('Now we catched them all!')\n",
    "\n",
    "    fin = {'posts':hse_career_posts}\n",
    "\n",
    "    with open('hse_career_department_website_posts.json', 'w') as f:\n",
    "        json.dump(hse_career_posts, f)\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
